{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2025-01-02...\n",
      "Fetching data for 2025-01-01...\n",
      "Fetching data for 2024-12-31...\n",
      "Fetching data for 2024-12-30...\n",
      "Fetching data for 2024-12-29...\n",
      "Fetching data for 2024-12-28...\n",
      "Fetching data for 2024-12-27...\n",
      "Fetching data for 2024-12-26...\n",
      "Fetching data for 2024-12-25...\n",
      "Fetching data for 2024-12-24...\n",
      "Fetching data for 2024-12-23...\n",
      "Fetching data for 2024-12-22...\n",
      "Fetching data for 2024-12-21...\n",
      "Fetching data for 2024-12-20...\n",
      "Fetching data for 2024-12-19...\n",
      "Fetching data for 2024-12-18...\n",
      "Fetching data for 2024-12-17...\n",
      "Fetching data for 2024-12-16...\n",
      "Fetching data for 2024-12-15...\n",
      "Fetching data for 2024-12-14...\n",
      "Fetching data for 2024-12-13...\n",
      "Fetching data for 2024-12-12...\n",
      "Fetching data for 2024-12-11...\n",
      "Fetching data for 2024-12-10...\n",
      "Fetching data for 2024-12-09...\n",
      "Fetching data for 2024-12-08...\n",
      "Fetching data for 2024-12-07...\n",
      "Fetching data for 2024-12-06...\n",
      "Fetching data for 2024-12-05...\n",
      "Fetching data for 2024-12-04...\n",
      "Fetching data for 2024-12-03...\n",
      "Fetching data for 2024-12-02...\n",
      "Fetching data for 2024-12-01...\n",
      "Fetching data for 2024-11-30...\n",
      "Fetching data for 2024-11-29...\n",
      "Fetching data for 2024-11-28...\n",
      "Fetching data for 2024-11-27...\n",
      "Fetching data for 2024-11-26...\n",
      "Fetching data for 2024-11-25...\n",
      "Fetching data for 2024-11-24...\n",
      "Fetching data for 2024-11-23...\n",
      "Fetching data for 2024-11-22...\n",
      "Fetching data for 2024-11-21...\n",
      "Fetching data for 2024-11-20...\n",
      "Fetching data for 2024-11-19...\n",
      "Fetching data for 2024-11-18...\n",
      "Fetching data for 2024-11-17...\n",
      "Fetching data for 2024-11-16...\n",
      "Fetching data for 2024-11-15...\n",
      "Fetching data for 2024-11-14...\n",
      "Fetching data for 2024-11-13...\n",
      "Fetching data for 2024-11-12...\n",
      "Fetching data for 2024-11-11...\n",
      "Fetching data for 2024-11-10...\n",
      "Fetching data for 2024-11-09...\n",
      "Fetching data for 2024-11-08...\n",
      "Fetching data for 2024-11-07...\n",
      "Fetching data for 2024-11-06...\n",
      "Fetching data for 2024-11-05...\n",
      "Fetching data for 2024-11-04...\n",
      "Fetching data for 2024-11-03...\n",
      "Fetching data for 2024-11-02...\n",
      "Fetching data for 2024-11-01...\n",
      "Fetching data for 2024-10-31...\n",
      "Fetching data for 2024-10-30...\n",
      "Fetching data for 2024-10-29...\n",
      "Fetching data for 2024-10-28...\n",
      "Fetching data for 2024-10-27...\n",
      "Fetching data for 2024-10-26...\n",
      "Fetching data for 2024-10-25...\n",
      "Fetching data for 2024-10-24...\n",
      "Fetching data for 2024-10-23...\n",
      "Fetching data for 2024-10-22...\n",
      "Fetching data for 2024-10-21...\n",
      "Fetching data for 2024-10-20...\n",
      "Fetching data for 2024-10-19...\n",
      "Fetching data for 2024-10-18...\n",
      "Fetching data for 2024-10-17...\n",
      "Fetching data for 2024-10-16...\n",
      "Fetching data for 2024-10-15...\n",
      "Fetching data for 2024-10-14...\n",
      "Fetching data for 2024-10-13...\n",
      "Fetching data for 2024-10-12...\n",
      "Fetching data for 2024-10-11...\n",
      "Fetching data for 2024-10-10...\n",
      "Fetching data for 2024-10-09...\n",
      "Fetching data for 2024-10-08...\n",
      "Fetching data for 2024-10-07...\n",
      "Fetching data for 2024-10-06...\n",
      "Fetching data for 2024-10-05...\n",
      "Fetching data for 2024-10-04...\n",
      "Fetching data for 2024-10-03...\n",
      "Fetching data for 2024-10-02...\n",
      "Fetching data for 2024-10-01...\n",
      "Fetching data for 2024-09-30...\n",
      "Fetching data for 2024-09-29...\n",
      "Fetching data for 2024-09-28...\n",
      "Fetching data for 2024-09-27...\n",
      "Fetching data for 2024-09-26...\n",
      "Fetching data for 2024-09-25...\n",
      "Fetching data for 2024-09-24...\n",
      "Fetching data for 2024-09-23...\n",
      "Fetching data for 2024-09-22...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Fetching data for 2024-09-21...\n",
      "Fetching data for 2024-09-20...\n",
      "Fetching data for 2024-09-19...\n",
      "Fetching data for 2024-09-18...\n",
      "Fetching data for 2024-09-17...\n",
      "Fetching data for 2024-09-16...\n",
      "Fetching data for 2024-09-15...\n",
      "Fetching data for 2024-09-14...\n",
      "Fetching data for 2024-09-13...\n",
      "Fetching data for 2024-09-12...\n",
      "Fetching data for 2024-09-11...\n",
      "Fetching data for 2024-09-10...\n",
      "Fetching data for 2024-09-09...\n",
      "Fetching data for 2024-09-08...\n",
      "Fetching data for 2024-09-07...\n",
      "Fetching data for 2024-09-06...\n",
      "Fetching data for 2024-09-05...\n",
      "Fetching data for 2024-09-04...\n",
      "Fetching data for 2024-09-03...\n",
      "Fetching data for 2024-09-02...\n",
      "Fetching data for 2024-09-01...\n",
      "Fetching data for 2024-08-31...\n",
      "Fetching data for 2024-08-30...\n",
      "Fetching data for 2024-08-29...\n",
      "Fetching data for 2024-08-28...\n",
      "Fetching data for 2024-08-27...\n",
      "Fetching data for 2024-08-26...\n",
      "Fetching data for 2024-08-25...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Fetching data for 2024-08-24...\n",
      "Fetching data for 2024-08-23...\n",
      "Fetching data for 2024-08-22...\n",
      "Fetching data for 2024-08-21...\n",
      "Fetching data for 2024-08-20...\n",
      "Fetching data for 2024-08-19...\n",
      "Fetching data for 2024-08-18...\n",
      "Fetching data for 2024-08-17...\n",
      "Fetching data for 2024-08-16...\n",
      "Fetching data for 2024-08-15...\n",
      "Fetching data for 2024-08-14...\n",
      "Fetching data for 2024-08-13...\n",
      "Fetching data for 2024-08-12...\n",
      "Fetching data for 2024-08-11...\n",
      "Fetching data for 2024-08-10...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Fetching data for 2024-08-09...\n",
      "Fetching data for 2024-08-08...\n",
      "Fetching data for 2024-08-07...\n",
      "Fetching data for 2024-08-06...\n",
      "Fetching data for 2024-08-05...\n",
      "Fetching data for 2024-08-04...\n",
      "Fetching data for 2024-08-03...\n",
      "Fetching data for 2024-08-02...\n",
      "Fetching data for 2024-08-01...\n",
      "Fetching data for 2024-07-31...\n",
      "Fetching data for 2024-07-30...\n",
      "Fetching data for 2024-07-29...\n",
      "Fetching data for 2024-07-28...\n",
      "Fetching data for 2024-07-27...\n",
      "Fetching data for 2024-07-26...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Fetching data for 2024-07-25...\n",
      "Fetching data for 2024-07-24...\n",
      "Fetching data for 2024-07-23...\n",
      "Fetching data for 2024-07-22...\n",
      "Fetching data for 2024-07-21...\n",
      "Fetching data for 2024-07-20...\n",
      "Fetching data for 2024-07-19...\n",
      "Fetching data for 2024-07-18...\n",
      "Fetching data for 2024-07-17...\n",
      "Fetching data for 2024-07-16...\n",
      "Fetching data for 2024-07-15...\n",
      "Fetching data for 2024-07-14...\n",
      "Fetching data for 2024-07-13...\n",
      "Fetching data for 2024-07-12...\n",
      "Fetching data for 2024-07-11...\n",
      "Fetching data for 2024-07-10...\n",
      "Fetching data for 2024-07-09...\n",
      "Fetching data for 2024-07-08...\n",
      "Fetching data for 2024-07-07...\n",
      "Fetching data for 2024-07-06...\n",
      "Fetching data for 2024-07-05...\n",
      "Fetching data for 2024-07-04...\n",
      "Fetching data for 2024-07-03...\n",
      "Fetching data for 2024-07-02...\n",
      "Fetching data for 2024-07-01...\n",
      "Fetching data for 2024-06-30...\n",
      "Fetching data for 2024-06-29...\n",
      "Fetching data for 2024-06-28...\n",
      "Fetching data for 2024-06-27...\n",
      "Fetching data for 2024-06-26...\n",
      "Fetching data for 2024-06-25...\n",
      "Fetching data for 2024-06-24...\n",
      "Fetching data for 2024-06-23...\n",
      "Fetching data for 2024-06-22...\n",
      "Fetching data for 2024-06-21...\n",
      "Fetching data for 2024-06-20...\n",
      "Fetching data for 2024-06-19...\n",
      "Fetching data for 2024-06-18...\n",
      "Fetching data for 2024-06-17...\n",
      "Fetching data for 2024-06-16...\n",
      "Fetching data for 2024-06-15...\n",
      "Fetching data for 2024-06-14...\n",
      "Fetching data for 2024-06-13...\n",
      "Fetching data for 2024-06-12...\n",
      "Fetching data for 2024-06-11...\n",
      "Fetching data for 2024-06-10...\n",
      "Fetching data for 2024-06-09...\n",
      "Fetching data for 2024-06-08...\n",
      "Fetching data for 2024-06-07...\n",
      "Fetching data for 2024-06-06...\n",
      "Fetching data for 2024-06-05...\n",
      "Fetching data for 2024-06-04...\n",
      "Fetching data for 2024-06-03...\n",
      "Fetching data for 2024-06-02...\n",
      "Fetching data for 2024-06-01...\n",
      "Fetching data for 2024-05-31...\n",
      "Fetching data for 2024-05-30...\n",
      "Fetching data for 2024-05-29...\n",
      "Fetching data for 2024-05-28...\n",
      "Fetching data for 2024-05-27...\n",
      "Fetching data for 2024-05-26...\n",
      "Fetching data for 2024-05-25...\n",
      "Fetching data for 2024-05-24...\n",
      "Fetching data for 2024-05-23...\n",
      "Fetching data for 2024-05-22...\n",
      "Fetching data for 2024-05-21...\n",
      "Fetching data for 2024-05-20...\n",
      "Fetching data for 2024-05-19...\n",
      "Fetching data for 2024-05-18...\n",
      "Fetching data for 2024-05-17...\n",
      "Fetching data for 2024-05-16...\n",
      "Fetching data for 2024-05-15...\n",
      "Fetching data for 2024-05-14...\n",
      "Fetching data for 2024-05-13...\n",
      "Fetching data for 2024-05-12...\n",
      "Fetching data for 2024-05-11...\n",
      "Fetching data for 2024-05-10...\n",
      "Fetching data for 2024-05-09...\n",
      "Fetching data for 2024-05-08...\n",
      "Fetching data for 2024-05-07...\n",
      "Fetching data for 2024-05-06...\n",
      "Fetching data for 2024-05-05...\n",
      "Fetching data for 2024-05-04...\n",
      "Fetching data for 2024-05-03...\n",
      "Fetching data for 2024-05-02...\n",
      "Fetching data for 2024-05-01...\n",
      "Fetching data for 2024-04-30...\n",
      "Fetching data for 2024-04-29...\n",
      "Fetching data for 2024-04-28...\n",
      "Fetching data for 2024-04-27...\n",
      "Fetching data for 2024-04-26...\n",
      "Fetching data for 2024-04-25...\n",
      "Fetching data for 2024-04-24...\n",
      "Fetching data for 2024-04-23...\n",
      "Fetching data for 2024-04-22...\n",
      "Fetching data for 2024-04-21...\n",
      "Fetching data for 2024-04-20...\n",
      "Fetching data for 2024-04-19...\n",
      "Fetching data for 2024-04-18...\n",
      "Fetching data for 2024-04-17...\n",
      "Fetching data for 2024-04-16...\n",
      "Fetching data for 2024-04-15...\n",
      "Fetching data for 2024-04-14...\n",
      "Fetching data for 2024-04-13...\n",
      "Fetching data for 2024-04-12...\n",
      "Fetching data for 2024-04-11...\n",
      "Fetching data for 2024-04-10...\n",
      "Fetching data for 2024-04-09...\n",
      "Fetching data for 2024-04-08...\n",
      "Fetching data for 2024-04-07...\n",
      "Fetching data for 2024-04-06...\n",
      "Fetching data for 2024-04-05...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Rate limit hit. Waiting before retrying...\n",
      "Fetching data for 2024-04-04...\n",
      "Fetching data for 2024-04-03...\n",
      "Fetching data for 2024-04-02...\n",
      "Fetching data for 2024-04-01...\n",
      "Fetching data for 2024-03-31...\n",
      "Fetching data for 2024-03-30...\n",
      "Fetching data for 2024-03-29...\n",
      "Fetching data for 2024-03-28...\n",
      "Fetching data for 2024-03-27...\n",
      "Fetching data for 2024-03-26...\n",
      "Fetching data for 2024-03-25...\n",
      "Fetching data for 2024-03-24...\n",
      "Fetching data for 2024-03-23...\n",
      "Fetching data for 2024-03-22...\n",
      "Fetching data for 2024-03-21...\n",
      "Fetching data for 2024-03-20...\n",
      "Fetching data for 2024-03-19...\n",
      "Fetching data for 2024-03-18...\n",
      "Fetching data for 2024-03-17...\n",
      "Fetching data for 2024-03-16...\n",
      "Fetching data for 2024-03-15...\n",
      "Fetching data for 2024-03-14...\n",
      "Fetching data for 2024-03-13...\n",
      "Fetching data for 2024-03-12...\n",
      "Fetching data for 2024-03-11...\n",
      "Fetching data for 2024-03-10...\n",
      "Fetching data for 2024-03-09...\n",
      "Fetching data for 2024-03-08...\n",
      "Fetching data for 2024-03-07...\n",
      "Fetching data for 2024-03-06...\n",
      "Fetching data for 2024-03-05...\n",
      "Fetching data for 2024-03-04...\n",
      "Fetching data for 2024-03-03...\n",
      "Fetching data for 2024-03-02...\n",
      "Fetching data for 2024-03-01...\n",
      "Fetching data for 2024-02-29...\n",
      "Fetching data for 2024-02-28...\n",
      "Fetching data for 2024-02-27...\n",
      "Fetching data for 2024-02-26...\n",
      "Fetching data for 2024-02-25...\n",
      "Fetching data for 2024-02-24...\n",
      "Fetching data for 2024-02-23...\n",
      "Fetching data for 2024-02-22...\n",
      "Fetching data for 2024-02-21...\n",
      "Fetching data for 2024-02-20...\n",
      "Fetching data for 2024-02-19...\n",
      "Fetching data for 2024-02-18...\n",
      "Fetching data for 2024-02-17...\n",
      "Fetching data for 2024-02-16...\n",
      "Fetching data for 2024-02-15...\n",
      "Fetching data for 2024-02-14...\n",
      "Fetching data for 2024-02-13...\n",
      "Fetching data for 2024-02-12...\n",
      "Fetching data for 2024-02-11...\n",
      "Fetching data for 2024-02-10...\n",
      "Fetching data for 2024-02-09...\n",
      "Fetching data for 2024-02-08...\n",
      "Fetching data for 2024-02-07...\n",
      "Fetching data for 2024-02-06...\n",
      "Fetching data for 2024-02-05...\n",
      "Fetching data for 2024-02-04...\n",
      "Fetching data for 2024-02-03...\n",
      "Fetching data for 2024-02-02...\n",
      "Fetching data for 2024-02-01...\n",
      "Fetching data for 2024-01-31...\n",
      "Fetching data for 2024-01-30...\n",
      "Fetching data for 2024-01-29...\n",
      "Fetching data for 2024-01-28...\n",
      "Fetching data for 2024-01-27...\n",
      "Fetching data for 2024-01-26...\n",
      "Fetching data for 2024-01-25...\n",
      "Fetching data for 2024-01-24...\n",
      "Fetching data for 2024-01-23...\n",
      "Fetching data for 2024-01-22...\n",
      "Fetching data for 2024-01-21...\n",
      "Fetching data for 2024-01-20...\n",
      "Fetching data for 2024-01-19...\n",
      "Fetching data for 2024-01-18...\n",
      "Fetching data for 2024-01-17...\n",
      "Fetching data for 2024-01-16...\n",
      "Fetching data for 2024-01-15...\n",
      "Fetching data for 2024-01-14...\n",
      "Fetching data for 2024-01-13...\n",
      "Fetching data for 2024-01-12...\n",
      "Fetching data for 2024-01-11...\n",
      "Fetching data for 2024-01-10...\n",
      "Fetching data for 2024-01-09...\n",
      "Fetching data for 2024-01-08...\n",
      "Fetching data for 2024-01-07...\n",
      "Fetching data for 2024-01-06...\n",
      "Fetching data for 2024-01-05...\n",
      "Fetching data for 2024-01-04...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>price</th>\n",
       "      <th>volume_24h</th>\n",
       "      <th>volume_change_24h</th>\n",
       "      <th>percent_change_1h</th>\n",
       "      <th>percent_change_24h</th>\n",
       "      <th>percent_change_7d</th>\n",
       "      <th>percent_change_30d</th>\n",
       "      <th>percent_change_60d</th>\n",
       "      <th>percent_change_90d</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>market_cap_dominance</th>\n",
       "      <th>fully_diluted_market_cap</th>\n",
       "      <th>circulating_supply</th>\n",
       "      <th>total_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>DOGEVERSE</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5439.851909</td>\n",
       "      <td>104.061</td>\n",
       "      <td>2.217943</td>\n",
       "      <td>12.837254</td>\n",
       "      <td>16.310021</td>\n",
       "      <td>-31.290667</td>\n",
       "      <td>-48.793458</td>\n",
       "      <td>-49.063209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224922.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>DOGEVERSE</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5439.851909</td>\n",
       "      <td>104.061</td>\n",
       "      <td>2.217943</td>\n",
       "      <td>12.837254</td>\n",
       "      <td>16.310021</td>\n",
       "      <td>-31.290667</td>\n",
       "      <td>-48.793458</td>\n",
       "      <td>-49.063209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224922.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>DOGEVERSE</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5439.851909</td>\n",
       "      <td>104.061</td>\n",
       "      <td>2.217943</td>\n",
       "      <td>12.837254</td>\n",
       "      <td>16.310021</td>\n",
       "      <td>-31.290667</td>\n",
       "      <td>-48.793458</td>\n",
       "      <td>-49.063209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224922.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>DOGEVERSE</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5439.851909</td>\n",
       "      <td>104.061</td>\n",
       "      <td>2.217943</td>\n",
       "      <td>12.837254</td>\n",
       "      <td>16.310021</td>\n",
       "      <td>-31.290667</td>\n",
       "      <td>-48.793458</td>\n",
       "      <td>-49.063209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224922.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>DOGEVERSE</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5439.851909</td>\n",
       "      <td>104.061</td>\n",
       "      <td>2.217943</td>\n",
       "      <td>12.837254</td>\n",
       "      <td>16.310021</td>\n",
       "      <td>-31.290667</td>\n",
       "      <td>-48.793458</td>\n",
       "      <td>-49.063209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224922.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     symbol     price   volume_24h  volume_change_24h  \\\n",
       "108  2024-12-26  DOGEVERSE  0.000011  5439.851909            104.061   \n",
       "94   2024-12-27  DOGEVERSE  0.000011  5439.851909            104.061   \n",
       "80   2024-12-28  DOGEVERSE  0.000011  5439.851909            104.061   \n",
       "66   2024-12-29  DOGEVERSE  0.000011  5439.851909            104.061   \n",
       "52   2024-12-30  DOGEVERSE  0.000011  5439.851909            104.061   \n",
       "\n",
       "     percent_change_1h  percent_change_24h  percent_change_7d  \\\n",
       "108           2.217943           12.837254          16.310021   \n",
       "94            2.217943           12.837254          16.310021   \n",
       "80            2.217943           12.837254          16.310021   \n",
       "66            2.217943           12.837254          16.310021   \n",
       "52            2.217943           12.837254          16.310021   \n",
       "\n",
       "     percent_change_30d  percent_change_60d  percent_change_90d  market_cap  \\\n",
       "108          -31.290667          -48.793458          -49.063209         0.0   \n",
       "94           -31.290667          -48.793458          -49.063209         0.0   \n",
       "80           -31.290667          -48.793458          -49.063209         0.0   \n",
       "66           -31.290667          -48.793458          -49.063209         0.0   \n",
       "52           -31.290667          -48.793458          -49.063209         0.0   \n",
       "\n",
       "     market_cap_dominance  fully_diluted_market_cap  circulating_supply  \\\n",
       "108                   0.0                2224922.39                 0.0   \n",
       "94                    0.0                2224922.39                 0.0   \n",
       "80                    0.0                2224922.39                 0.0   \n",
       "66                    0.0                2224922.39                 0.0   \n",
       "52                    0.0                2224922.39                 0.0   \n",
       "\n",
       "     total_supply  \n",
       "108  2.000000e+11  \n",
       "94   2.000000e+11  \n",
       "80   2.000000e+11  \n",
       "66   2.000000e+11  \n",
       "52   2.000000e+11  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "async def fetch_data_batch(session, url, headers, params, retries=3):\n",
    "    \"\"\"\n",
    "    Fetches data for a batch of cryptocurrencies asynchronously with retries.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            async with session.get(url, headers=headers, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    return await response.json()\n",
    "                elif response.status == 429:\n",
    "                    print(\"Rate limit hit. Waiting before retrying...\")\n",
    "                    await asyncio.sleep(10)  \n",
    "                else:\n",
    "                    print(f\"Failed to fetch: HTTP {response.status}\")\n",
    "                    return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data: {str(e)}\")\n",
    "            await asyncio.sleep(5)\n",
    "    return None\n",
    "\n",
    "async def fetch_crypto_data_async(api_key, symbols):\n",
    "    \"\"\"\n",
    "    Fetches cryptocurrency data for multiple symbols in batches asynchronously.\n",
    "    \"\"\"\n",
    "    base_url = \"https://pro-api.coinmarketcap.com/v1/cryptocurrency/quotes/latest\"\n",
    "    headers = {\n",
    "        'X-CMC_PRO_API_KEY': api_key,\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    batch_size = 10\n",
    "    symbol_batches = [symbols[i:i + batch_size] for i in range(0, len(symbols), batch_size)]\n",
    "    tasks = []\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for batch in symbol_batches:\n",
    "            params = {\n",
    "                'symbol': ','.join(batch),\n",
    "                'convert': 'USD'\n",
    "            }\n",
    "            tasks.append(fetch_data_batch(session, base_url, headers, params))\n",
    "        \n",
    "        responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    all_data = []\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    for response in responses:\n",
    "        if response:\n",
    "            try:\n",
    "                for symbol, coin_data in response['data'].items():\n",
    "                    quote_data = coin_data['quote']['USD']\n",
    "                    record = {\n",
    "                        'date': current_date,\n",
    "                        'symbol': symbol,\n",
    "                        'price': quote_data['price'],\n",
    "                        'volume_24h': quote_data['volume_24h'],\n",
    "                        'volume_change_24h': quote_data['volume_change_24h'],\n",
    "                        'percent_change_1h': quote_data['percent_change_1h'],\n",
    "                        'percent_change_24h': quote_data['percent_change_24h'],\n",
    "                        'percent_change_7d': quote_data['percent_change_7d'],\n",
    "                        'percent_change_30d': quote_data['percent_change_30d'],\n",
    "                        'percent_change_60d': quote_data['percent_change_60d'],\n",
    "                        'percent_change_90d': quote_data['percent_change_90d'],\n",
    "                        'market_cap': quote_data['market_cap'],\n",
    "                        'market_cap_dominance': quote_data['market_cap_dominance'],\n",
    "                        'fully_diluted_market_cap': quote_data['fully_diluted_market_cap'],\n",
    "                        'circulating_supply': coin_data.get('circulating_supply'),\n",
    "                        'total_supply': coin_data.get('total_supply')\n",
    "                    }\n",
    "                    all_data.append(record)\n",
    "            except KeyError as e:\n",
    "                print(f\"Error processing response: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "async def create_historical_dataset_async(api_key, symbols, days=365):\n",
    "    \"\"\"\n",
    "    Creates a dataset with historical data for the specified number of days asynchronously.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    current_date = datetime.now()\n",
    "    \n",
    "    for i in range(days):\n",
    "        date = current_date - timedelta(days=i)\n",
    "        print(f\"Fetching data for {date.strftime('%Y-%m-%d')}...\")\n",
    "        \n",
    "        df = await fetch_crypto_data_async(api_key, symbols)\n",
    "        if not df.empty:\n",
    "            df['date'] = date.strftime('%Y-%m-%d')\n",
    "            all_data.append(df)\n",
    "        \n",
    "        await asyncio.sleep(2)\n",
    "    \n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df.sort_values(['price', 'date'])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "async def main():\n",
    "    API_KEY = \"6377a87f-a8ee-4c6f-a62b-f63faefc3e20\"\n",
    "    symbols =  [\"BTC\", \"ETH\", \"BNB\", \"USDT\", \"ADA\", \n",
    "             \"SOL\", \"AVAX\", \"MATIC\", \"LINK\", \"XRP\", \n",
    "             \"DOGEVERSE\", \"SEAL\", \"WAI\", \"SPONGEV2\", \"FLOKI\"]\n",
    "    historical_data = await create_historical_dataset_async(API_KEY, symbols, days=365)\n",
    "    return historical_data\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  \n",
    "\n",
    "historical_data = asyncio.run(main())\n",
    "historical_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.to_csv('coindata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price</th>\n",
       "      <th>volume_24h</th>\n",
       "      <th>volume_change_24h</th>\n",
       "      <th>percent_change_1h</th>\n",
       "      <th>percent_change_24h</th>\n",
       "      <th>percent_change_7d</th>\n",
       "      <th>percent_change_30d</th>\n",
       "      <th>percent_change_60d</th>\n",
       "      <th>percent_change_90d</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>market_cap_dominance</th>\n",
       "      <th>fully_diluted_market_cap</th>\n",
       "      <th>circulating_supply</th>\n",
       "      <th>total_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5.110000e+03</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5.110000e+03</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5.110000e+03</td>\n",
       "      <td>5.110000e+03</td>\n",
       "      <td>5.110000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2554.500000</td>\n",
       "      <td>7253.026896</td>\n",
       "      <td>1.351442e+10</td>\n",
       "      <td>84.225428</td>\n",
       "      <td>0.517851</td>\n",
       "      <td>7.516885</td>\n",
       "      <td>9.894528</td>\n",
       "      <td>-1.745500</td>\n",
       "      <td>105.962861</td>\n",
       "      <td>475.959421</td>\n",
       "      <td>2.061116e+11</td>\n",
       "      <td>6.030397</td>\n",
       "      <td>2.260807e+11</td>\n",
       "      <td>7.024872e+11</td>\n",
       "      <td>7.264552e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1475.274268</td>\n",
       "      <td>24936.468000</td>\n",
       "      <td>2.790993e+10</td>\n",
       "      <td>82.974505</td>\n",
       "      <td>0.967497</td>\n",
       "      <td>4.441910</td>\n",
       "      <td>13.144233</td>\n",
       "      <td>38.250076</td>\n",
       "      <td>133.650979</td>\n",
       "      <td>1470.252005</td>\n",
       "      <td>4.882953e+11</td>\n",
       "      <td>14.285604</td>\n",
       "      <td>5.157677e+11</td>\n",
       "      <td>2.468554e+12</td>\n",
       "      <td>2.481916e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.439782e+03</td>\n",
       "      <td>-18.938300</td>\n",
       "      <td>-1.245967</td>\n",
       "      <td>-0.048914</td>\n",
       "      <td>-2.742910</td>\n",
       "      <td>-35.313520</td>\n",
       "      <td>-48.793458</td>\n",
       "      <td>-49.063209</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.224922e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.980473e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1277.250000</td>\n",
       "      <td>0.498831</td>\n",
       "      <td>6.897065e+06</td>\n",
       "      <td>43.211000</td>\n",
       "      <td>-0.003284</td>\n",
       "      <td>4.284448</td>\n",
       "      <td>1.803887</td>\n",
       "      <td>-20.099391</td>\n",
       "      <td>29.089398</td>\n",
       "      <td>27.480096</td>\n",
       "      <td>9.371048e+08</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>1.790789e+09</td>\n",
       "      <td>1.980473e+07</td>\n",
       "      <td>1.204752e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2554.500000</td>\n",
       "      <td>1.708536</td>\n",
       "      <td>1.280900e+09</td>\n",
       "      <td>65.175050</td>\n",
       "      <td>0.354825</td>\n",
       "      <td>7.852316</td>\n",
       "      <td>5.139098</td>\n",
       "      <td>-6.201385</td>\n",
       "      <td>57.326175</td>\n",
       "      <td>43.668348</td>\n",
       "      <td>2.491419e+10</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>3.569912e+10</td>\n",
       "      <td>4.463683e+08</td>\n",
       "      <td>7.956692e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3831.750000</td>\n",
       "      <td>207.436583</td>\n",
       "      <td>1.010157e+10</td>\n",
       "      <td>115.723300</td>\n",
       "      <td>0.839037</td>\n",
       "      <td>9.547808</td>\n",
       "      <td>11.943735</td>\n",
       "      <td>-0.124775</td>\n",
       "      <td>109.195739</td>\n",
       "      <td>101.002565</td>\n",
       "      <td>1.373202e+11</td>\n",
       "      <td>4.016600</td>\n",
       "      <td>1.413244e+11</td>\n",
       "      <td>3.513978e+10</td>\n",
       "      <td>9.998674e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5109.000000</td>\n",
       "      <td>97454.535636</td>\n",
       "      <td>1.054920e+11</td>\n",
       "      <td>340.916700</td>\n",
       "      <td>3.394859</td>\n",
       "      <td>16.869658</td>\n",
       "      <td>52.020350</td>\n",
       "      <td>129.382091</td>\n",
       "      <td>431.594698</td>\n",
       "      <td>5783.994741</td>\n",
       "      <td>1.930061e+12</td>\n",
       "      <td>56.504500</td>\n",
       "      <td>2.046545e+12</td>\n",
       "      <td>9.601110e+12</td>\n",
       "      <td>9.671506e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         price    volume_24h  volume_change_24h  \\\n",
       "count  5110.000000   5110.000000  5.110000e+03        5110.000000   \n",
       "mean   2554.500000   7253.026896  1.351442e+10          84.225428   \n",
       "std    1475.274268  24936.468000  2.790993e+10          82.974505   \n",
       "min       0.000000      0.000011  5.439782e+03         -18.938300   \n",
       "25%    1277.250000      0.498831  6.897065e+06          43.211000   \n",
       "50%    2554.500000      1.708536  1.280900e+09          65.175050   \n",
       "75%    3831.750000    207.436583  1.010157e+10         115.723300   \n",
       "max    5109.000000  97454.535636  1.054920e+11         340.916700   \n",
       "\n",
       "       percent_change_1h  percent_change_24h  percent_change_7d  \\\n",
       "count        5110.000000         5110.000000        5110.000000   \n",
       "mean            0.517851            7.516885           9.894528   \n",
       "std             0.967497            4.441910          13.144233   \n",
       "min            -1.245967           -0.048914          -2.742910   \n",
       "25%            -0.003284            4.284448           1.803887   \n",
       "50%             0.354825            7.852316           5.139098   \n",
       "75%             0.839037            9.547808          11.943735   \n",
       "max             3.394859           16.869658          52.020350   \n",
       "\n",
       "       percent_change_30d  percent_change_60d  percent_change_90d  \\\n",
       "count         5110.000000         5110.000000         5110.000000   \n",
       "mean            -1.745500          105.962861          475.959421   \n",
       "std             38.250076          133.650979         1470.252005   \n",
       "min            -35.313520          -48.793458          -49.063209   \n",
       "25%            -20.099391           29.089398           27.480096   \n",
       "50%             -6.201385           57.326175           43.668348   \n",
       "75%             -0.124775          109.195739          101.002565   \n",
       "max            129.382091          431.594698         5783.994741   \n",
       "\n",
       "         market_cap  market_cap_dominance  fully_diluted_market_cap  \\\n",
       "count  5.110000e+03           5110.000000              5.110000e+03   \n",
       "mean   2.061116e+11              6.030397              2.260807e+11   \n",
       "std    4.882953e+11             14.285604              5.157677e+11   \n",
       "min    0.000000e+00              0.000000              2.224922e+06   \n",
       "25%    9.371048e+08              0.027400              1.790789e+09   \n",
       "50%    2.491419e+10              0.730700              3.569912e+10   \n",
       "75%    1.373202e+11              4.016600              1.413244e+11   \n",
       "max    1.930061e+12             56.504500              2.046545e+12   \n",
       "\n",
       "       circulating_supply  total_supply  \n",
       "count        5.110000e+03  5.110000e+03  \n",
       "mean         7.024872e+11  7.264552e+11  \n",
       "std          2.468554e+12  2.481916e+12  \n",
       "min          0.000000e+00  1.980473e+07  \n",
       "25%          1.980473e+07  1.204752e+08  \n",
       "50%          4.463683e+08  7.956692e+08  \n",
       "75%          3.513978e+10  9.998674e+10  \n",
       "max          9.601110e+12  9.671506e+12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coindata.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Volatility\"] = df[[\"percent_change_1h\", \"percent_change_24h\", \"percent_change_7d\"]].std(axis=1)\n",
    "\n",
    "df[\"Normalized_Volatility\"] = df[\"Volatility\"] / df[\"Volatility\"].max()\n",
    "df[\"Normalized_MarketCapDominance\"] = 1 / (df[\"market_cap_dominance\"] + 1e-6) \n",
    "df[\"Normalized_VolumeChange\"] = 1 - df[\"volume_change_24h\"] / df[\"volume_change_24h\"].max()\n",
    "\n",
    "weights = {\n",
    "    \"Normalized_Volatility\": 0.4,  \n",
    "    \"Normalized_MarketCapDominance\": 0.4, \n",
    "    \"Normalized_VolumeChange\": 0.2, \n",
    "}\n",
    "\n",
    "df[\"Composite_Score\"] = (\n",
    "    weights[\"Normalized_Volatility\"] * df[\"Normalized_Volatility\"] +\n",
    "    weights[\"Normalized_MarketCapDominance\"] * df[\"Normalized_MarketCapDominance\"] +\n",
    "    weights[\"Normalized_VolumeChange\"] * df[\"Normalized_VolumeChange\"]\n",
    ")\n",
    "\n",
    "risk_thresholds = {\n",
    "    \"Low\": df[\"Composite_Score\"].quantile(0.40),\n",
    "    \"Medium\": df[\"Composite_Score\"].quantile(0.60),\n",
    "}\n",
    "\n",
    "def classify_risk(score):\n",
    "    if score <= risk_thresholds[\"Low\"]:\n",
    "        return \"Low\"\n",
    "    elif score <= risk_thresholds[\"Medium\"]:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "df[\"Risk\"] = df[\"Composite_Score\"].apply(classify_risk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
